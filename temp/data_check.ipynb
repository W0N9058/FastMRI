{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 편향성 확인을 위한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 경로와 키 설정\n",
    "data_dir = '/home/Data/train/image'\n",
    "input_key = 'image_input'\n",
    "target_key = 'image_label'\n",
    "\n",
    "def load_data(file_path, input_key, target_key, device='cuda'):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        masked_data = torch.tensor(np.array(f[input_key]), device=device)\n",
    "        original_data = torch.tensor(np.array(f[target_key]), device=device)\n",
    "    return masked_data, original_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존의 data/load_data 모듈을 활용할 수 있는 방법은 없을까?\n",
    "우리에게 주어진 데이터셋의 구조를 한 번 더 확인해볼 필요가 있을 듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_deviation(masked, original):\n",
    "    deviation = torch.abs(original - masked)\n",
    "    return deviation\n",
    "\n",
    "def visualize_deviation_histogram(deviation, title='Deviation between Original and Masked Data'):\n",
    "    deviation_cpu = deviation.cpu().numpy()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(deviation_cpu.flatten(), bins=50, alpha=0.75)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Deviation')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "def analyze_bias(data_dir, input_key, target_key, device='cuda'):\n",
    "    all_deviation = []\n",
    "\n",
    "    # 데이터 파일 리스트 가져오기\n",
    "    data_files = list(Path(data_dir).rglob('*.h5'))\n",
    "    \n",
    "    for file_path in tqdm(data_files, desc=\"Processing files\"):\n",
    "        masked_data, original_data = load_data(file_path, input_key, target_key, device)\n",
    "        deviation = calculate_deviation(masked_data, original_data)\n",
    "        all_deviation.append(deviation.cpu().numpy())\n",
    "    \n",
    "    # 전체 편차 데이터 결합\n",
    "    all_deviation = np.concatenate(all_deviation)\n",
    "    visualize_deviation_histogram(torch.tensor(all_deviation), title=\"Overall Deviation Histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떻게 시각화해야 데이터의 편향성을 쉽게 찾아낼 수 있을까?\n",
    "관련 모듈이 존재할까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_bias(data_dir, input_key, target_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 형태 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 경로와 키 설정\n",
    "data_dir = '/home/Data/train/image'\n",
    "input_key = 'image_input'\n",
    "target_key = 'image_label'\n",
    "\n",
    "def load_data(file_path, input_key, target_key, device='cuda'):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        masked_data = torch.tensor(np.array(f[input_key]), device=device)\n",
    "        original_data = torch.tensor(np.array(f[target_key]), device=device)\n",
    "    return masked_data, original_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "def check_hdf5_files_structure(data_dir):\n",
    "    data_dir = Path(data_dir)\n",
    "    hdf5_files = list(data_dir.glob(\"*.h5\"))  # .h5 파일만 선택\n",
    "\n",
    "    for hdf5_file in hdf5_files:\n",
    "        print(f\"Checking file: {hdf5_file}\")\n",
    "        with h5py.File(hdf5_file, 'r') as f:\n",
    "            def print_attrs(name, obj):\n",
    "                if isinstance(obj, h5py.Dataset):\n",
    "                    print(f\"Dataset: {name}\")\n",
    "                    print(f\" - Shape: {obj.shape}\")\n",
    "                    print(f\" - Dtype: {obj.dtype}\")\n",
    "                elif isinstance(obj, h5py.Group):\n",
    "                    print(f\"Group: {name}\")\n",
    "            \n",
    "            f.visititems(print_attrs)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# 데이터 디렉토리 설정\n",
    "data_dir = '/home/Data/train/image'\n",
    "\n",
    "# 디렉토리 구조 확인\n",
    "check_hdf5_files_structure(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 픽셀값 범위 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file: /home/Data/train/image/brain_acc4_57.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.183310011285357e-06, 0.0005742062930949032]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.619081664714031e-06, 0.0005073858774267137]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [8.071409865806345e-06, 0.000559419218916446]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_1.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.146978881180985e-06, 0.0007418789900839329]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.231533239362761e-06, 0.0005357774207368493]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [9.31897375266999e-06, 0.0007074805325828493]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_48.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (14, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.3657081530691357e-06, 0.0007966027478687465]\n",
      "Dataset: image_input\n",
      " - Shape: (14, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.818883669737261e-06, 0.0005201254971325397]\n",
      "Dataset: image_label\n",
      " - Shape: (14, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [7.807740075804759e-06, 0.0006566537776961923]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc4_89.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.919789716950618e-06, 0.0006706895073875785]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [5.439872893475695e-06, 0.0005304809310473502]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [9.682517884357367e-06, 0.0006597632309421897]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_11.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.719143705893657e-06, 0.000839538814034313]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.794085841946071e-06, 0.0006443511811085045]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [7.354766694334103e-06, 0.000723334786016494]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_116.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.3156154586322373e-06, 0.0006875029648654163]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.63442222806043e-06, 0.0005102363647893071]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [6.889204996696208e-06, 0.0005995838437229395]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_85.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [2.902576625274378e-06, 0.0007901340140961111]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.327435024402803e-06, 0.0005417719949036837]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [8.716212505532894e-06, 0.0005909220781177282]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_107.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.080066562688444e-06, 0.0008478283998556435]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [2.9569753223768203e-06, 0.0006042294553481042]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [7.704161362198647e-06, 0.0006268270080909133]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc5_58.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.7322619138867594e-06, 0.0006745024584233761]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.859674390900182e-06, 0.0005838751676492393]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [9.44595376495272e-06, 0.0006342962151393294]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc4_110.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [5.258342298475327e-06, 0.0007929719868116081]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [5.689798854291439e-06, 0.0006030736840330064]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [1.0142992323380895e-05, 0.0007866768864914775]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc4_71.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.509668658807641e-06, 0.0005555421230383217]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.001478373538703e-06, 0.00048524478916078806]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [6.930911695235409e-06, 0.0005609779618680477]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_64.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.2156798372161575e-06, 0.0008276623557321727]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.60419914816157e-06, 0.0005678937304764986]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [1.067340144800255e-05, 0.0005394694744609296]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc5_43.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.5420282529230462e-06, 0.0007410492398776114]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.1561565922165755e-06, 0.0005929605686105788]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [8.832052117213607e-06, 0.0006980245816521347]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc5_74.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [6.45811496724491e-07, 0.0006612884462811053]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [1.037339416143368e-06, 0.00055308936862275]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [1.5870407423790311e-06, 0.0006907973438501358]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_111.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.0442520255746786e-06, 0.0007411392289213836]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.223536168661667e-06, 0.0005521304556168616]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [6.4889022723946255e-06, 0.000703402329236269]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc4_113.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.564624305203324e-06, 0.0006728232838213444]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.837624601350399e-06, 0.0006238454952836037]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [8.671750947542023e-06, 0.0006309020682238042]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_92.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.7444010558829177e-06, 0.0005355507601052523]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.5987425235362025e-06, 0.00035929997102357447]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [8.487357263220474e-06, 0.0004053674638271332]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc5_40.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.3843084565887693e-06, 0.0006634301389567554]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.878146799252136e-06, 0.0006138831377029419]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [8.24522339826217e-06, 0.0006316262879408896]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc4_1.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.7693221202061977e-06, 0.0006943634944036603]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.193905169813661e-06, 0.0007277682307176292]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [7.116767392290058e-06, 0.0006861936417408288]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc5_95.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.563924110494554e-06, 0.0007064229575917125]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.877983999700518e-06, 0.0006046683993190527]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [6.731891517119948e-06, 0.0006754155620001256]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_120.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (14, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [2.679572617125814e-06, 0.0006505245692096651]\n",
      "Dataset: image_input\n",
      " - Shape: (14, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [2.695449666134664e-06, 0.0005421708920039237]\n",
      "Dataset: image_label\n",
      " - Shape: (14, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [5.992156275169691e-06, 0.0006310400203801692]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc4_42.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.925529654225102e-06, 0.0006210968131199479]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.321318101574434e-06, 0.0005122041329741478]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [7.452199497492984e-06, 0.0006156133022159338]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc5_35.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.694335418913397e-06, 0.0006797764217481017]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.5052933071710868e-06, 0.0005753463483415544]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [7.489319614251144e-06, 0.000688300933688879]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_102.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.92627771361731e-06, 0.0007077696500346065]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.19880370827741e-06, 0.0005976642132736742]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [9.020342986332253e-06, 0.0007099008071236312]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc5_29.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.736137725558365e-06, 0.0006995591102167964]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [5.500179213413503e-06, 0.0006935676210559905]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [1.0089904208143707e-05, 0.0006850528297945857]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc4_45.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.219054517307086e-06, 0.0006197572802193463]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.5381721065496095e-06, 0.00046399221173487604]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [7.682050636503845e-06, 0.0006194604211486876]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc5_107.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.8492011046619155e-06, 0.0007518887869082391]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [5.090482318337308e-06, 0.0006527642253786325]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [9.884790415526368e-06, 0.0007081781513988972]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_90.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.229895582990139e-06, 0.0007447322132065892]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.0776193398196483e-06, 0.0005212462856434286]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [7.205852853076067e-06, 0.0007006280357018113]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc4_27.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.173671984768589e-06, 0.0006719037774018943]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.7343875192163978e-06, 0.0005463402485474944]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [6.742746336385608e-06, 0.000661328958813101]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc4_103.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [5.826997039548587e-06, 0.0007835167343728244]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [5.3667604333895724e-06, 0.000743646698538214]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [1.106697254726896e-05, 0.0007701193098910153]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc4_86.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [5.015725491830381e-06, 0.0008642363245598972]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [5.266224889055593e-06, 0.0008807601989246905]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [1.0612327059789095e-05, 0.0008684166241437197]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc4_80.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.114958301215665e-06, 0.0007104726973921061]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.29525107392692e-06, 0.0006709450390189886]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [7.348238796112128e-06, 0.0006982478662393987]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_6.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [5.092888841318199e-06, 0.0008069220348261297]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.837966571358265e-06, 0.0005302962381392717]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [1.0507744264032226e-05, 0.0007688951445743442]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc4_15.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.189636001683539e-06, 0.0005995102692395449]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.081551651324844e-06, 0.0005508633912540972]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [7.718114829913247e-06, 0.000595223915297538]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_47.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.126057774556102e-06, 0.0007851698901504278]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.271394573152065e-06, 0.0005549260531552136]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [9.971280633180868e-06, 0.0006950255483388901]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_74.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.755837380798766e-06, 0.0009755463688634336]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.718207492260262e-06, 0.000627137953415513]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [1.0452689821249805e-05, 0.0007461074274033308]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc5_84.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.56554562333622e-06, 0.0005655561690218747]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [5.347456408344442e-06, 0.0005158000276423991]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [9.743388545757625e-06, 0.0005514542572200298]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc8_98.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.573482328851242e-06, 0.0008686582441441715]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [4.7457115215365775e-06, 0.0007009872933849692]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [9.573164788889699e-06, 0.0006786193698644638]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc5_37.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.8067855712142773e-06, 0.0006721497047692537]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.931897481379565e-06, 0.0005131249199621379]\n",
      "Dataset: image_label\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [7.5443117566464934e-06, 0.0006376525852829218]\n",
      "\n",
      "\n",
      "Checking file: /home/Data/train/image/brain_acc5_101.h5\n",
      "Dataset: image_grappa\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n",
      " - Pixel Value Range: [3.2542102417210117e-06, 0.0006981790065765381]\n",
      "Dataset: image_input\n",
      " - Shape: (16, 384, 384)\n",
      " - Dtype: float32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 43\u001b[0m\n\u001b[1;32m     37\u001b[0m data_dirs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/Data/train/image\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/Data/leaderboard/acc9/image\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     40\u001b[0m ]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# 디렉토리 구조 확인\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[43mcheck_hdf5_files_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dirs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 31\u001b[0m, in \u001b[0;36mcheck_hdf5_files_structure\u001b[0;34m(data_dirs)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, h5py\u001b[38;5;241m.\u001b[39mGroup):\n\u001b[1;32m     29\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisititems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprint_attrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError reading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhdf5_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/h5py/_hl/group.py:674\u001b[0m, in \u001b[0;36mGroup.visititems\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    672\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_d(name)\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(name, \u001b[38;5;28mself\u001b[39m[name])\n\u001b[0;32m--> 674\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:406\u001b[0m, in \u001b[0;36mh5py.h5o.visit\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:353\u001b[0m, in \u001b[0;36mh5py.h5o.cb_obj_simple\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/h5py/_hl/group.py:673\u001b[0m, in \u001b[0;36mGroup.visititems.<locals>.proxy\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Use the text name of the object, not bytes \"\"\"\u001b[39;00m\n\u001b[1;32m    672\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_d(name)\n\u001b[0;32m--> 673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m, in \u001b[0;36mcheck_hdf5_files_structure.<locals>.print_attrs\u001b[0;34m(name, obj)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Calculate and print the range of pixel values\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Load the dataset into memory\u001b[39;00m\n\u001b[1;32m     25\u001b[0m min_val \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mmin()\n\u001b[1;32m     26\u001b[0m max_val \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mmax()\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/h5py/_hl/dataset.py:758\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "def check_hdf5_files_structure(data_dirs):\n",
    "    for data_dir in data_dirs:\n",
    "        data_dir = Path(data_dir)\n",
    "        hdf5_files = list(data_dir.glob(\"*.h5\"))  # .h5 파일만 선택\n",
    "\n",
    "        if not hdf5_files:\n",
    "            print(f\"No HDF5 files found in directory: {data_dir}\")\n",
    "            continue\n",
    "\n",
    "        for hdf5_file in hdf5_files:\n",
    "            print(f\"Checking file: {hdf5_file}\")\n",
    "            try:\n",
    "                with h5py.File(hdf5_file, 'r') as f:\n",
    "                    def print_attrs(name, obj):\n",
    "                        if isinstance(obj, h5py.Dataset):\n",
    "                            print(f\"Dataset: {name}\")\n",
    "                            print(f\" - Shape: {obj.shape}\")\n",
    "                            print(f\" - Dtype: {obj.dtype}\")\n",
    "                            \n",
    "                            # Calculate and print the range of pixel values\n",
    "                            data = obj[()]  # Load the dataset into memory\n",
    "                            min_val = data.min()\n",
    "                            max_val = data.max()\n",
    "                            print(f\" - Pixel Value Range: [{min_val}, {max_val}]\")\n",
    "                        elif isinstance(obj, h5py.Group):\n",
    "                            print(f\"Group: {name}\")\n",
    "                    \n",
    "                    f.visititems(print_attrs)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {hdf5_file}: {e}\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "# 데이터 디렉토리 설정\n",
    "data_dirs = [\n",
    "    '/home/Data/train/image',\n",
    "    '/home/Data/leaderboard/acc9/image'\n",
    "]\n",
    "\n",
    "# 디렉토리 구조 확인\n",
    "check_hdf5_files_structure(data_dirs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-space 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 디렉토리 설정\n",
    "data_dir = '/home/Data/train/kspace'\n",
    "\n",
    "# 디렉토리 구조 확인\n",
    "check_hdf5_files_structure(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함께 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "def check_hdf5_files_structure(file_path):\n",
    "    print(f\"Checking file: {file_path}\")\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        def print_attrs(name, obj):\n",
    "            if isinstance(obj, h5py.Dataset):\n",
    "                print(f\"Dataset: {name}\")\n",
    "                print(f\" - Shape: {obj.shape}\")\n",
    "                print(f\" - Dtype: {obj.dtype}\")\n",
    "            elif isinstance(obj, h5py.Group):\n",
    "                print(f\"Group: {name}\")\n",
    "        \n",
    "        f.visititems(print_attrs)\n",
    "    print(\"\\n\")\n",
    "\n",
    "def find_common_files(dir1, dir2):\n",
    "    dir1_files = {f.name for f in Path(dir1).glob(\"*.h5\")}\n",
    "    dir2_files = {f.name for f in Path(dir2).glob(\"*.h5\")}\n",
    "    common_files = dir1_files.intersection(dir2_files)\n",
    "    return common_files\n",
    "\n",
    "# 디렉토리 설정\n",
    "data_dir_kspace = '/home/Data/train/kspace'\n",
    "data_dir_image = '/home/Data/train/image'\n",
    "\n",
    "# 공통 파일 찾기\n",
    "common_files = find_common_files(data_dir_kspace, data_dir_image)\n",
    "print(f\"Common files: {common_files}\\n\")\n",
    "\n",
    "# 공통 파일의 구조 확인\n",
    "for file_name in common_files:\n",
    "    print(f\"Checking structures for file: {file_name}\")\n",
    "    \n",
    "    kspace_file_path = Path(data_dir_kspace) / file_name\n",
    "    image_file_path = Path(data_dir_image) / file_name\n",
    "    \n",
    "    print(\"Kspace file structure:\")\n",
    "    check_hdf5_files_structure(kspace_file_path)\n",
    "    \n",
    "    print(\"Image file structure:\")\n",
    "    check_hdf5_files_structure(image_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "def check_hdf5_files_structure(file_path):\n",
    "    print(f\"Checking file: {file_path}\")\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        def print_attrs(name, obj):\n",
    "            if isinstance(obj, h5py.Dataset):\n",
    "                print(f\"Dataset: {name}\")\n",
    "                print(f\" - Shape: {obj.shape}\")\n",
    "                print(f\" - Dtype: {obj.dtype}\")\n",
    "            elif isinstance(obj, h5py.Group):\n",
    "                print(f\"Group: {name}\")\n",
    "        \n",
    "        f.visititems(print_attrs)\n",
    "    print(\"\\n\")\n",
    "\n",
    "def find_common_files(dir1, dir2):\n",
    "    dir1_files = {f.name for f in Path(dir1).glob(\"*.h5\")}\n",
    "    dir2_files = {f.name for f in Path(dir2).glob(\"*.h5\")}\n",
    "    common_files = dir1_files.intersection(dir2_files)\n",
    "    return common_files\n",
    "\n",
    "def print_mask_values(file_path):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        if 'mask' in f:\n",
    "            mask = f['mask'][:]\n",
    "            print(f\"mask values from {file_path}:\")\n",
    "            print(mask)\n",
    "        else:\n",
    "            print(f\"No mask dataset found in {file_path}\")\n",
    "\n",
    "# 디렉토리 설정\n",
    "data_dir_kspace = '/home/Data/leaderboard/acc9/kspace'\n",
    "data_dir_image = '/home/Data/leaderboard/acc9/image'\n",
    "# data_dir_kspace = '/root/result/test_Varnet/reconstructions_leaderboard/private'\n",
    "# data_dir_image = '/root/result/test_Varnet/reconstructions_leaderboard/private'\n",
    "\n",
    "# 공통 파일 찾기\n",
    "common_files = find_common_files(data_dir_kspace, data_dir_image)\n",
    "print(f\"Common files: {common_files}\\n\")\n",
    "\n",
    "# 공통 파일의 구조 확인 및 mask 값 출력\n",
    "for file_name in common_files:\n",
    "    print(f\"Checking structures for file: {file_name}\")\n",
    "    \n",
    "    kspace_file_path = Path(data_dir_kspace) / file_name\n",
    "    image_file_path = Path(data_dir_image) / file_name\n",
    "    \n",
    "    print(\"Kspace file structure:\")\n",
    "    check_hdf5_files_structure(kspace_file_path)\n",
    "    \n",
    "    print(\"Image file structure:\")\n",
    "    check_hdf5_files_structure(image_file_path)\n",
    "    \n",
    "    # mask 값 출력\n",
    "    print(\"Kspace file mask values:\")\n",
    "    print_mask_values(kspace_file_path)\n",
    "    \n",
    "    print(\"Image file mask values:\")\n",
    "    print_mask_values(image_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fastmri.data.subsample import RandomMaskFunc\n",
    "\n",
    "# RandomMaskFunc 초기화\n",
    "mask_func = RandomMaskFunc(center_fractions=[0.04], accelerations=[8])\n",
    "\n",
    "# k-space 데이터 형태 정의\n",
    "shape = (1, 256, 256)  # 3차원으로 설정 (num_slices, height, width)\n",
    "\n",
    "# 마스크 생성\n",
    "mask = mask_func(shape)\n",
    "\n",
    "# 마스크 값 출력\n",
    "print(\"Generated mask values:\")\n",
    "print(mask)\n",
    "\n",
    "# 마스크 시각화\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.imshow(mask[0], aspect='auto', cmap='gray')  # 첫 번째 slice의 마스크 시각화\n",
    "plt.xlabel('k-space columns')\n",
    "plt.ylabel('k-space rows')\n",
    "plt.title('k-space Mask')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSIM 값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSIM(nn.Module):\n",
    "    \"\"\"Layer to compute the SSIM loss between a pair of images\"\"\"\n",
    "    def __init__(self):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.mu_x_pool   = nn.AvgPool2d(3, 1)\n",
    "        self.mu_y_pool   = nn.AvgPool2d(3, 1)\n",
    "        self.sig_x_pool  = nn.AvgPool2d(3, 1)\n",
    "        self.sig_y_pool  = nn.AvgPool2d(3, 1)\n",
    "        self.sig_xy_pool = nn.AvgPool2d(3, 1)\n",
    "\n",
    "        # 입력 경계의 반사를 사용하여 상/하/좌/우에 입력 텐서를 추가로 채웁니다.\n",
    "        self.refl = nn.ReflectionPad2d(1)\n",
    "\n",
    "        self.C1 = 0.001 ** 2\n",
    "        self.C2 = 0.03 ** 2\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # shape : (xh, xw) -> (xh + 2, xw + 2)\n",
    "        x = self.refl(x) \n",
    "        # shape : (yh, yw) -> (yh + 2, yw + 2)\n",
    "        y = self.refl(y)\n",
    "\n",
    "        mu_x = self.mu_x_pool(x)\n",
    "        mu_y = self.mu_y_pool(y)\n",
    "\n",
    "        sigma_x  = self.sig_x_pool(x ** 2) - mu_x ** 2\n",
    "        sigma_y  = self.sig_y_pool(y ** 2) - mu_y ** 2\n",
    "        sigma_xy = self.sig_xy_pool(x * y) - mu_x * mu_y\n",
    "\n",
    "        SSIM_n = (2 * mu_x * mu_y + self.C1) * (2 * sigma_xy + self.C2)\n",
    "        SSIM_d = (mu_x ** 2 + mu_y ** 2 + self.C1) * (sigma_x + sigma_y + self.C2)\n",
    "\n",
    "        # SSIM score\n",
    "        return torch.clamp((SSIM_n / SSIM_d) / 2, 0, 1)\n",
    "\n",
    "        # Loss function\n",
    "        # return torch.clamp((1 - SSIM_n / SSIM_d) / 2, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hdf5_datasets(file_path, dataset_names):\n",
    "    datasets = {}\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        for name in dataset_names:\n",
    "            if name in f:\n",
    "                datasets[name] = f[name][:]\n",
    "            else:\n",
    "                print(f\"No {name} dataset found in {file_path}\")\n",
    "                datasets[name] = None\n",
    "    return datasets\n",
    "\n",
    "def calculate_ssim_for_images(label, input_data, grappa, ssim_module):\n",
    "    if label is not None and input_data is not None:\n",
    "        ssim_input = ssim_module(label, input_data)\n",
    "        print(f\"SSIM between label and input:\\n{ssim_input}\")\n",
    "\n",
    "    if label is not None and grappa is not None:\n",
    "        ssim_grappa = ssim_module(label, grappa)\n",
    "        print(f\"SSIM between label and grappa:\\n{ssim_grappa}\")\n",
    "\n",
    "data_dir_image = '/home/Data/train/image'\n",
    "common_files = {f.name for f in Path(data_dir_image).glob(\"*.h5\")}\n",
    "dataset_names = ['image_label', 'image_input', 'image_grappa']\n",
    "\n",
    "ssim_module = SSIM()\n",
    "\n",
    "for file_name in common_files:\n",
    "    print(f\"Checking structures for file: {file_name}\")\n",
    "    \n",
    "    image_file_path = Path(data_dir_image) / file_name\n",
    "    \n",
    "    datasets = read_hdf5_datasets(image_file_path, dataset_names)\n",
    "    \n",
    "    label = datasets['image_label']\n",
    "    input_data = datasets['image_input']\n",
    "    grappa = datasets['image_grappa']\n",
    "    \n",
    "    if label is not None:\n",
    "        label = torch.tensor(label, dtype=torch.float32).unsqueeze(1)\n",
    "    if input_data is not None:\n",
    "        input_data = torch.tensor(input_data, dtype=torch.float32).unsqueeze(1)\n",
    "    if grappa is not None:\n",
    "        grappa = torch.tensor(grappa, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    calculate_ssim_for_images(label, input_data, grappa, ssim_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_values(label, input_data, grappa):\n",
    "    print(\"Checking data values...\")\n",
    "    if label is not None:\n",
    "        print(\"Label data:\")\n",
    "        print(label)\n",
    "    if input_data is not None:\n",
    "        print(\"Input data:\")\n",
    "        print(input_data)\n",
    "    if grappa is not None:\n",
    "        print(\"Grappa data:\")\n",
    "        print(grappa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor(data):\n",
    "    if data is not None:\n",
    "        return torch.tensor(data, dtype=torch.float32).unsqueeze(1)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "class SSIM(nn.Module):\n",
    "    \"\"\"Layer to compute the SSIM loss between a pair of images\"\"\"\n",
    "    def __init__(self):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.mu_x_pool   = nn.AvgPool2d(3, 1)\n",
    "        self.mu_y_pool   = nn.AvgPool2d(3, 1)\n",
    "        self.sig_x_pool  = nn.AvgPool2d(3, 1)\n",
    "        self.sig_y_pool  = nn.AvgPool2d(3, 1)\n",
    "        self.sig_xy_pool = nn.AvgPool2d(3, 1)\n",
    "\n",
    "        self.refl = nn.ReflectionPad2d(1)\n",
    "\n",
    "        # Adjusted constants for numerical stability\n",
    "        self.C1 = 0.01\n",
    "        self.C2 = 0.03\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = self.refl(x) \n",
    "        y = self.refl(y)\n",
    "\n",
    "        mu_x = self.mu_x_pool(x)\n",
    "        mu_y = self.mu_y_pool(y)\n",
    "\n",
    "        sigma_x  = self.sig_x_pool(x ** 2) - mu_x ** 2\n",
    "        sigma_y  = self.sig_y_pool(y ** 2) - mu_y ** 2\n",
    "        sigma_xy = self.sig_xy_pool(x * y) - mu_x * mu_y\n",
    "\n",
    "        SSIM_n = (2 * mu_x * mu_y + self.C1) * (2 * sigma_xy + self.C2)\n",
    "        SSIM_d = (mu_x ** 2 + mu_y ** 2 + self.C1) * (sigma_x + sigma_y + self.C2)\n",
    "\n",
    "        return torch.clamp((SSIM_n / SSIM_d) / 2, 0, 1)\n",
    "\n",
    "def read_hdf5_datasets(file_path, dataset_names):\n",
    "    datasets = {}\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        for name in dataset_names:\n",
    "            if name in f:\n",
    "                datasets[name] = f[name][:]\n",
    "            else:\n",
    "                print(f\"No {name} dataset found in {file_path}\")\n",
    "                datasets[name] = None\n",
    "    return datasets\n",
    "\n",
    "def convert_to_tensor(data):\n",
    "    if data is not None:\n",
    "        data = data.astype(np.float32)\n",
    "        # Normalize data to range [0, 1]\n",
    "        data_min, data_max = np.min(data), np.max(data)\n",
    "        data = (data - data_min) / (data_max - data_min)\n",
    "        return torch.tensor(data, dtype=torch.float32).unsqueeze(1)\n",
    "    return None\n",
    "\n",
    "def check_data_values(label, input_data, grappa):\n",
    "    print(\"Checking data values...\")\n",
    "    if label is not None:\n",
    "        print(\"Label data:\")\n",
    "        print(label)\n",
    "    if input_data is not None:\n",
    "        print(\"Input data:\")\n",
    "        print(input_data)\n",
    "    if grappa is not None:\n",
    "        print(\"Grappa data:\")\n",
    "        print(grappa)\n",
    "\n",
    "def calculate_ssim_for_images(label, input_data, grappa, ssim_module):\n",
    "    if label is not None and input_data is not None:\n",
    "        ssim_input = ssim_module(label, input_data)\n",
    "        print(f\"SSIM between label and input:\\n{ssim_input}\")\n",
    "\n",
    "    if label is not None and grappa is not None:\n",
    "        ssim_grappa = ssim_module(label, grappa)\n",
    "        print(f\"SSIM between label and grappa:\\n{ssim_grappa}\")\n",
    "\n",
    "data_dir_image = '/home/Data/leaderboard/acc9/image'\n",
    "common_files = {f.name for f in Path(data_dir_image).glob(\"*.h5\")}\n",
    "dataset_names = ['image_label', 'image_input', 'image_grappa']\n",
    "\n",
    "ssim_module = SSIM()\n",
    "\n",
    "for file_name in common_files:\n",
    "    print(f\"Checking structures for file: {file_name}\")\n",
    "    \n",
    "    image_file_path = Path(data_dir_image) / file_name\n",
    "    \n",
    "    datasets = read_hdf5_datasets(image_file_path, dataset_names)\n",
    "    \n",
    "    label = convert_to_tensor(datasets['image_label'])\n",
    "    input_data = convert_to_tensor(datasets['image_input'])\n",
    "    grappa = convert_to_tensor(datasets['image_grappa'])\n",
    "    \n",
    "    check_data_values(label, input_data, grappa)\n",
    "    \n",
    "    calculate_ssim_for_images(label, input_data, grappa, ssim_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
